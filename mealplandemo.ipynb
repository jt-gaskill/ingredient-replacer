{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200075b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentma/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/vincentma/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/vincentma/.cache/kagglehub/datasets/wilmerarltstrmberg/recipe-dataset-over-2m/versions/2\n",
      "Available columns: ['title', 'ingredients', 'directions']\n",
      "Dataset shape: (2231141, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>['1 c. firmly packed brown sugar', '1/2 c. eva...</td>\n",
       "      <td>['In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>['1 small jar chipped beef, cut up', '4 boned ...</td>\n",
       "      <td>['Place chipped beef on bottom of baking dish....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>['2 (16 oz.) pkg. frozen corn', '1 (8 oz.) pkg...</td>\n",
       "      <td>['In a slow cooker, combine all ingredients. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>['1 large whole chicken', '2 (10 1/2 oz.) cans...</td>\n",
       "      <td>['Boil and debone chicken.', 'Put bite size pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>['1 c. peanut butter', '3/4 c. graham cracker ...</td>\n",
       "      <td>['Combine first four ingredients and press in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  ['1 c. firmly packed brown sugar', '1/2 c. eva...   \n",
       "1  Jewell Ball'S Chicken  ['1 small jar chipped beef, cut up', '4 boned ...   \n",
       "2            Creamy Corn  ['2 (16 oz.) pkg. frozen corn', '1 (8 oz.) pkg...   \n",
       "3          Chicken Funny  ['1 large whole chicken', '2 (10 1/2 oz.) cans...   \n",
       "4   Reeses Cups(Candy)    ['1 c. peanut butter', '3/4 c. graham cracker ...   \n",
       "\n",
       "                                          directions  \n",
       "0  ['In a heavy 2-quart saucepan, mix brown sugar...  \n",
       "1  ['Place chipped beef on bottom of baking dish....  \n",
       "2  ['In a slow cooker, combine all ingredients. C...  \n",
       "3  ['Boil and debone chicken.', 'Put bite size pi...  \n",
       "4  ['Combine first four ingredients and press in ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Download dataset (original code kept for compatibility)\n",
    "try:\n",
    "    import kagglehub\n",
    "    # Download latest version if not already downloaded\n",
    "    path = kagglehub.dataset_download(\"wilmerarltstrmberg/recipe-dataset-over-2m\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "except:\n",
    "    print(\"Could not download dataset with kagglehub. Using existing files.\")\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"recipes_data.csv\")\n",
    "\n",
    "# Print the columns to see what's available\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Only drop columns that exist\n",
    "columns_to_drop = []\n",
    "for col in ['source', 'link', 'NER', 'site']:\n",
    "    if col in df.columns:\n",
    "        columns_to_drop.append(col)\n",
    "\n",
    "if columns_to_drop:\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc8328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ingredients type: <class 'list'>\n",
      "Sample ingredients: ['1 c. firmly packed brown sugar', '1/2 c. evaporated milk', '1/2 tsp. vanilla']\n",
      "Creating TF-IDF representations...\n",
      "TF-IDF feature shape: (2231141, 100)\n",
      "Training Word2Vec model...\n",
      "Generating word embeddings...\n",
      "Extracting nutritional features...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert ingredient and directions columns from string to list\n",
    "try:\n",
    "    df['ingredients'] = df['ingredients'].apply(ast.literal_eval)\n",
    "    df['directions'] = df['directions'].apply(ast.literal_eval)\n",
    "except:\n",
    "    print(\"Columns may already be in list format.\")\n",
    "    \n",
    "# Check the format of the 'ingredients' column\n",
    "print(\"Sample ingredients type:\", type(df.loc[0, 'ingredients']))\n",
    "print(\"Sample ingredients:\", df.loc[0, 'ingredients'][:3])  # Show first 3 ingredients\n",
    "\n",
    "# IMPROVEMENT 1: Enhanced Data Representation\n",
    "# Preprocess ingredients to strings for TF-IDF\n",
    "def preprocess_ingredients(ingredients_list):\n",
    "    return \" \".join([ing.lower() for ing in ingredients_list])\n",
    "\n",
    "df['ingredients_text'] = df['ingredients'].apply(preprocess_ingredients)\n",
    "\n",
    "# Create TF-IDF representations\n",
    "print(\"Creating TF-IDF representations...\")\n",
    "tfidf = TfidfVectorizer(max_features=100)  # Reduced feature size for efficiency\n",
    "ingredient_features = tfidf.fit_transform(df['ingredients_text']).toarray()\n",
    "print(f\"TF-IDF feature shape: {ingredient_features.shape}\")\n",
    "\n",
    "# Create a corpus of ingredient words\n",
    "ingredient_corpus = [ing.split() for ingredients in df['ingredients'] for ing in ingredients]\n",
    "\n",
    "# Train Word2Vec\n",
    "print(\"Training Word2Vec model...\")\n",
    "ingredient_model = Word2Vec(sentences=ingredient_corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Average ingredient embeddings for each recipe\n",
    "def get_recipe_embedding(ingredients):\n",
    "    vectors = []\n",
    "    for ing in ingredients:\n",
    "        words = ing.split()\n",
    "        for word in words:\n",
    "            if word in ingredient_model.wv:\n",
    "                vectors.append(ingredient_model.wv[word])\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(50)\n",
    "\n",
    "print(\"Generating word embeddings...\")\n",
    "df['embedding'] = df['ingredients'].apply(get_recipe_embedding)\n",
    "\n",
    "# IMPROVEMENT 2: Add Nutritional and Category Features\n",
    "print(\"Extracting nutritional features...\")\n",
    "def extract_nutritional_features(ingredients):\n",
    "    # Simple heuristics for demonstration\n",
    "    protein_keywords = ['chicken', 'beef', 'fish', 'tofu', 'beans', 'lentils', 'eggs', 'pork', 'turkey', 'meat', 'lamb']\n",
    "    carb_keywords = ['rice', 'pasta', 'bread', 'potato', 'flour', 'sugar', 'corn', 'oat', 'cereal', 'noodle']\n",
    "    veg_keywords = ['spinach', 'broccoli', 'carrot', 'tomato', 'onion', 'celery', 'lettuce', 'cucumber', 'pepper', 'zucchini']\n",
    "    dairy_keywords = ['milk', 'cheese', 'cream', 'yogurt', 'butter', 'cheddar', 'mozzarella', 'parmesan']\n",
    "    \n",
    "    ingredients_text = ' '.join(ingredients).lower()\n",
    "    protein_score = sum([1 for k in protein_keywords if k in ingredients_text])\n",
    "    carb_score = sum([1 for k in carb_keywords if k in ingredients_text])\n",
    "    veg_score = sum([1 for k in veg_keywords if k in ingredients_text])\n",
    "    dairy_score = sum([1 for k in dairy_keywords if k in ingredients_text])\n",
    "    \n",
    "    return np.array([protein_score, carb_score, veg_score, dairy_score])\n",
    "\n",
    "df['nutritional_features'] = df['ingredients'].apply(extract_nutritional_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febdfa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cooking method features...\n",
      "Calculating recipe complexity...\n",
      "Creating synthetic meal plans...\n",
      "Calculating meaningful meal plan scores...\n",
      "Target score range: 3.80 - 10.00\n",
      "Simulating user preferences...\n"
     ]
    }
   ],
   "source": [
    "# Extract cooking method features\n",
    "print(\"Extracting cooking method features...\")\n",
    "def extract_cooking_features(directions):\n",
    "    baking_keywords = ['bake', 'oven', 'roast', 'broil']\n",
    "    frying_keywords = ['fry', 'sauté', 'pan', 'skillet']\n",
    "    boiling_keywords = ['boil', 'simmer', 'poach']\n",
    "    grilling_keywords = ['grill', 'barbecue', 'bbq']\n",
    "    \n",
    "    directions_text = ' '.join(directions).lower()\n",
    "    baking_score = sum([1 for k in baking_keywords if k in directions_text])\n",
    "    frying_score = sum([1 for k in frying_keywords if k in directions_text])\n",
    "    boiling_score = sum([1 for k in boiling_keywords if k in directions_text])\n",
    "    grilling_score = sum([1 for k in grilling_keywords if k in directions_text])\n",
    "    \n",
    "    return np.array([baking_score, frying_score, boiling_score, grilling_score])\n",
    "\n",
    "df['cooking_features'] = df['directions'].apply(extract_cooking_features)\n",
    "\n",
    "# Extract complexity based on number of ingredients and steps\n",
    "print(\"Calculating recipe complexity...\")\n",
    "df['ingredient_count'] = df['ingredients'].apply(len)\n",
    "df['direction_count'] = df['directions'].apply(len)\n",
    "df['complexity'] = (df['ingredient_count'] / df['ingredient_count'].max() + \n",
    "                    df['direction_count'] / df['direction_count'].max()) / 2 * 10  # Scale to 0-10\n",
    "\n",
    "# Create meal plans (synthetic data)\n",
    "print(\"Creating synthetic meal plans...\")\n",
    "def create_meal_plan(num_recipes=3):\n",
    "    return random.sample(list(df.index), num_recipes)\n",
    "\n",
    "# Create 1000 synthetic meal plans (increased from original 500)\n",
    "meal_plans = [create_meal_plan() for _ in range(1000)]\n",
    "\n",
    "# IMPROVEMENT 4: Implement a More Meaningful Target Variable\n",
    "print(\"Calculating meaningful meal plan scores...\")\n",
    "def calculate_meal_balance_score(recipe_indices):\n",
    "    # Get nutritional balance\n",
    "    meal_nutrition = np.sum([df.loc[idx, 'nutritional_features'] for idx in recipe_indices], axis=0)\n",
    "    \n",
    "    # Calculate balance score - reward diverse nutritional profile\n",
    "    protein, carbs, veg, dairy = meal_nutrition\n",
    "    # A balanced meal should have some of each, but not too much\n",
    "    balance = 10 - abs(protein - 2) - abs(carbs - 2) - abs(veg - 3) - abs(dairy - 1)\n",
    "    \n",
    "    # Add variety in cooking methods\n",
    "    cooking_methods = np.sum([df.loc[idx, 'cooking_features'] for idx in recipe_indices], axis=0)\n",
    "    cooking_variety = min(len([m for m in cooking_methods if m > 0]), 3)  # Up to 3 different methods\n",
    "    \n",
    "    # Add variety penalty (ingredients shouldn't overlap too much)\n",
    "    all_ingredients = []\n",
    "    for idx in recipe_indices:\n",
    "        all_ingredients.extend(df.loc[idx, 'ingredients'])\n",
    "    \n",
    "    unique_ratio = len(set(all_ingredients)) / len(all_ingredients) if all_ingredients else 0\n",
    "    variety_score = unique_ratio * 5\n",
    "    \n",
    "    # Complexity balance\n",
    "    complexities = [df.loc[idx, 'complexity'] for idx in recipe_indices]\n",
    "    complexity_balance = 3 - min(abs(max(complexities) - min(complexities)), 3)\n",
    "    \n",
    "    final_score = balance + variety_score + cooking_variety + complexity_balance\n",
    "    # Normalize to a 1-10 scale\n",
    "    return max(1, min(10, final_score))\n",
    "\n",
    "# Create more meaningful training data\n",
    "y_meaningful = np.array([calculate_meal_balance_score(plan) for plan in meal_plans])\n",
    "print(f\"Target score range: {y_meaningful.min():.2f} - {y_meaningful.max():.2f}\")\n",
    "\n",
    "# IMPROVEMENT 6: Implement User Preferences\n",
    "print(\"Simulating user preferences...\")\n",
    "# Simulate user preferences (in a real system, these would come from user data)\n",
    "user_preferences = {\n",
    "    'vegetarian': False,\n",
    "    'spice_level': 'medium',  # low, medium, high\n",
    "    'favorite_ingredients': ['chicken', 'garlic', 'olive oil'],\n",
    "    'disliked_ingredients': ['cilantro', 'mushrooms']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2159126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target scores after preferences: 8.96 - 16.17\n",
      "Preparing features for model training...\n"
     ]
    }
   ],
   "source": [
    "# Function to score recipes based on user preferences\n",
    "def user_preference_score(recipe_idx, preferences):\n",
    "    ingredients = ' '.join(df.loc[recipe_idx, 'ingredients']).lower()\n",
    "    \n",
    "    # Initialize score\n",
    "    score = 5.0\n",
    "    \n",
    "    # Check for vegetarian preference\n",
    "    if preferences['vegetarian']:\n",
    "        meat_keywords = ['chicken', 'beef', 'pork', 'fish', 'meat', 'turkey']\n",
    "        if any(meat in ingredients for meat in meat_keywords):\n",
    "            score -= 3.0\n",
    "    \n",
    "    # Check for favorite ingredients\n",
    "    for ingredient in preferences['favorite_ingredients']:\n",
    "        if ingredient in ingredients:\n",
    "            score += 0.5\n",
    "    \n",
    "    # Check for disliked ingredients\n",
    "    for ingredient in preferences['disliked_ingredients']:\n",
    "        if ingredient in ingredients:\n",
    "            score -= 1.0\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Adjust meal plan scores based on user preferences\n",
    "def adjust_meal_plan_score(plan_score, recipe_indices, user_prefs):\n",
    "    pref_score = sum(user_preference_score(idx, user_prefs) for idx in recipe_indices)\n",
    "    return plan_score + (pref_score / len(recipe_indices))\n",
    "\n",
    "# Apply user preferences to our target scores\n",
    "y_with_preferences = np.array([\n",
    "    adjust_meal_plan_score(\n",
    "        y_meaningful[i], \n",
    "        meal_plans[i], \n",
    "        user_preferences\n",
    "    ) for i in range(len(meal_plans))\n",
    "])\n",
    "\n",
    "print(f\"Target scores after preferences: {y_with_preferences.min():.2f} - {y_with_preferences.max():.2f}\")\n",
    "\n",
    "# Feature extraction for meal plans\n",
    "print(\"Preparing features for model training...\")\n",
    "def get_plan_features(plan):\n",
    "    # Extract Word2Vec embeddings\n",
    "    embeddings = np.array([df.loc[idx, 'embedding'] for idx in plan])\n",
    "    emb_avg = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    # Extract TF-IDF features\n",
    "    tfidf_features = np.array([ingredient_features[idx] for idx in plan])\n",
    "    tfidf_avg = np.mean(tfidf_features, axis=0)\n",
    "    \n",
    "    # Extract nutritional features\n",
    "    nutrition = np.array([df.loc[idx, 'nutritional_features'] for idx in plan])\n",
    "    nutrition_sum = np.sum(nutrition, axis=0)\n",
    "    \n",
    "    # Extract cooking features\n",
    "    cooking = np.array([df.loc[idx, 'cooking_features'] for idx in plan])\n",
    "    cooking_sum = np.sum(cooking, axis=0)\n",
    "    \n",
    "    # Complexity metrics\n",
    "    complexities = np.array([df.loc[idx, 'complexity'] for idx in plan])\n",
    "    complexity_features = np.array([\n",
    "        np.mean(complexities),\n",
    "        np.max(complexities) - np.min(complexities)  # Range of complexity\n",
    "    ])\n",
    "    \n",
    "    # Concatenate all features\n",
    "    return {\n",
    "        'embedding_input': emb_avg,\n",
    "        'tfidf_input': tfidf_avg,\n",
    "        'nutrition_input': nutrition_sum,\n",
    "        'cooking_input': cooking_sum,\n",
    "        'complexity_input': complexity_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a6e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building improved model architecture...\n",
      "Setting up callbacks for training...\n",
      "Implementing K-fold cross-validation...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare data for training\n",
    "X_features = [get_plan_features(plan) for plan in meal_plans]\n",
    "\n",
    "# IMPROVEMENT 3: Implement a More Sophisticated Model Architecture\n",
    "print(\"Building improved model architecture...\")\n",
    "\n",
    "# Define feature dimensions\n",
    "embedding_dim = 50\n",
    "tfidf_dim = ingredient_features.shape[1]\n",
    "nutrition_dim = 4\n",
    "cooking_dim = 4\n",
    "complexity_dim = 2\n",
    "\n",
    "def build_improved_model():\n",
    "    # Input layers\n",
    "    embedding_input = layers.Input(shape=(embedding_dim,), name='embedding_input')\n",
    "    tfidf_input = layers.Input(shape=(tfidf_dim,), name='tfidf_input')\n",
    "    nutrition_input = layers.Input(shape=(nutrition_dim,), name='nutrition_input')\n",
    "    cooking_input = layers.Input(shape=(cooking_dim,), name='cooking_input')\n",
    "    complexity_input = layers.Input(shape=(complexity_dim,), name='complexity_input')\n",
    "    \n",
    "    # Process embedding features\n",
    "    x1 = layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(embedding_input)\n",
    "    x1 = layers.Dropout(0.3)(x1)\n",
    "    x1 = layers.Dense(32, activation='relu')(x1)\n",
    "    \n",
    "    # Process TF-IDF features\n",
    "    x2 = layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(tfidf_input)\n",
    "    x2 = layers.Dropout(0.3)(x2)\n",
    "    \n",
    "    # Process nutrition features\n",
    "    x3 = layers.Dense(16, activation='relu')(nutrition_input)\n",
    "    \n",
    "    # Process cooking features\n",
    "    x4 = layers.Dense(8, activation='relu')(cooking_input)\n",
    "    \n",
    "    # Process complexity features\n",
    "    x5 = layers.Dense(4, activation='relu')(complexity_input)\n",
    "    \n",
    "    # Combine all features\n",
    "    concatenated = layers.Concatenate()([x1, x2, x3, x4, x5])\n",
    "    \n",
    "    # Final prediction layers\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(concatenated)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Model(\n",
    "        inputs=[embedding_input, tfidf_input, nutrition_input, cooking_input, complexity_input],\n",
    "        outputs=output\n",
    "    )\n",
    "    \n",
    "    # Compile with better optimizer and learning rate scheduling\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# IMPROVEMENT 5: Add Regularization and Early Stopping\n",
    "print(\"Setting up callbacks for training...\")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.0001\n",
    ")\n",
    "\n",
    "# IMPROVEMENT 7: Implement K-fold Cross-Validation\n",
    "print(\"Implementing K-fold cross-validation...\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare inputs for training\n",
    "def prepare_model_inputs(features_list):\n",
    "    return {\n",
    "        'embedding_input': np.array([f['embedding_input'] for f in features_list]),\n",
    "        'tfidf_input': np.array([f['tfidf_input'] for f in features_list]),\n",
    "        'nutrition_input': np.array([f['nutrition_input'] for f in features_list]),\n",
    "        'cooking_input': np.array([f['cooking_input'] for f in features_list]),\n",
    "        'complexity_input': np.array([f['complexity_input'] for f in features_list])\n",
    "    }\n",
    "\n",
    "# IMPROVEMENT 9: Implement Evaluation Metrics Specific to Recommendation Systems\n",
    "def precision_at_k(y_true, y_pred, k=5):\n",
    "    # Sort predictions and get top k\n",
    "    sorted_indices = np.argsort(y_pred)[::-1][:k]\n",
    "    # Count how many are relevant (above threshold in true values)\n",
    "    threshold = np.percentile(y_true, 70)  # Consider top 30% as relevant\n",
    "    num_relevant = sum(1 for i in sorted_indices if y_true[i] > threshold)\n",
    "    return num_relevant / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6172de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation training...\n",
      "\n",
      "Training fold 1/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 182.6813 - mae: 13.4493 - val_loss: 182.0894 - val_mae: 13.4414 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.9191 - mae: 11.5484 - val_loss: 143.8265 - val_mae: 11.8619 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.7674 - mae: 8.8459 - val_loss: 99.0111 - val_mae: 9.6901 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44.9811 - mae: 5.9466 - val_loss: 63.5885 - val_mae: 7.5443 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.9369 - mae: 4.0130 - val_loss: 43.5888 - val_mae: 6.3257 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.7995 - mae: 3.0239 - val_loss: 27.7543 - val_mae: 5.0754 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8645 - mae: 2.5270 - val_loss: 17.6998 - val_mae: 4.0237 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5860 - mae: 2.2872 - val_loss: 12.0712 - val_mae: 3.2667 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8608 - mae: 2.0792 - val_loss: 6.7715 - val_mae: 2.4177 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1223 - mae: 2.2836 - val_loss: 6.4684 - val_mae: 2.3585 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1974 - mae: 1.9158 - val_loss: 3.6254 - val_mae: 1.6676 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3640 - mae: 2.0402 - val_loss: 3.3626 - val_mae: 1.6028 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0029 - mae: 1.9230 - val_loss: 2.4803 - val_mae: 1.2956 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1591 - mae: 1.7509 - val_loss: 1.6481 - val_mae: 0.9825 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4767 - mae: 1.8244 - val_loss: 1.4841 - val_mae: 0.9004 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8641 - mae: 1.6900 - val_loss: 1.3937 - val_mae: 0.8530 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8824 - mae: 1.7008 - val_loss: 1.3432 - val_mae: 0.8466 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1585 - mae: 1.5669 - val_loss: 1.2360 - val_mae: 0.7568 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5795 - mae: 1.6633 - val_loss: 1.2765 - val_mae: 0.8043 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1357 - mae: 1.5618 - val_loss: 1.3859 - val_mae: 0.8551 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5798 - mae: 1.7112 - val_loss: 1.4657 - val_mae: 0.8905 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7148 - mae: 1.6692 - val_loss: 1.4260 - val_mae: 0.8703 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5500 - mae: 1.6798 - val_loss: 1.2318 - val_mae: 0.7636 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9251 - mae: 1.5688 - val_loss: 1.1581 - val_mae: 0.7242 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5625 - mae: 1.4358 - val_loss: 1.1554 - val_mae: 0.7074 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6931 - mae: 1.4608 - val_loss: 1.2257 - val_mae: 0.7141 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1339 - mae: 1.5962 - val_loss: 1.2153 - val_mae: 0.7224 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9394 - mae: 1.5724 - val_loss: 1.0828 - val_mae: 0.6614 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8340 - mae: 1.5200 - val_loss: 1.1375 - val_mae: 0.6801 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4177 - mae: 1.4643 - val_loss: 1.1255 - val_mae: 0.6767 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0864 - mae: 1.3580 - val_loss: 1.1602 - val_mae: 0.7079 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3108 - mae: 1.4262 - val_loss: 1.1276 - val_mae: 0.6368 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3401 - mae: 1.4183 - val_loss: 1.1115 - val_mae: 0.6494 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4820 - mae: 1.4539 - val_loss: 1.0932 - val_mae: 0.6600 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2454 - mae: 1.4173 - val_loss: 1.0941 - val_mae: 0.6660 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0589 - mae: 1.3413 - val_loss: 1.0911 - val_mae: 0.6658 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8437 - mae: 1.2799 - val_loss: 1.0830 - val_mae: 0.6560 - learning_rate: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9755 - mae: 1.5097 - val_loss: 1.0783 - val_mae: 0.6646 - learning_rate: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3606 - mae: 1.4361 - val_loss: 1.1086 - val_mae: 0.6810 - learning_rate: 2.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2740 - mae: 1.3779 - val_loss: 1.1063 - val_mae: 0.6820 - learning_rate: 2.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1626 - mae: 1.3584 - val_loss: 1.1272 - val_mae: 0.7049 - learning_rate: 2.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0200 - mae: 1.3239 - val_loss: 1.1224 - val_mae: 0.6950 - learning_rate: 2.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0988 - mae: 1.3758 - val_loss: 1.1121 - val_mae: 0.6981 - learning_rate: 2.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9946 - mae: 1.3135 - val_loss: 1.1172 - val_mae: 0.7016 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9833 - mae: 1.3524 - val_loss: 1.1303 - val_mae: 0.7083 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5636 - mae: 1.4743 - val_loss: 1.1340 - val_mae: 0.7087 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4501 - mae: 1.4728 - val_loss: 1.1226 - val_mae: 0.6986 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1538 - mae: 1.3611 - val_loss: 1.1109 - val_mae: 0.6914 - learning_rate: 1.0000e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0505 - mae: 0.6872\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Fold 1 - MAE: 0.6646, Precision@5: 0.2000\n",
      "\n",
      "Training fold 2/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 209.5881 - mae: 14.3973 - val_loss: 169.6011 - val_mae: 12.9699 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.2592 - mae: 12.5942 - val_loss: 126.4553 - val_mae: 11.1047 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.1253 - mae: 10.1997 - val_loss: 77.2118 - val_mae: 8.4092 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.3594 - mae: 7.5167 - val_loss: 48.6324 - val_mae: 6.3584 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43.9541 - mae: 5.7583 - val_loss: 39.2833 - val_mae: 5.5869 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.2345 - mae: 4.7037 - val_loss: 29.8708 - val_mae: 4.7397 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7778 - mae: 3.7256 - val_loss: 24.1368 - val_mae: 4.1583 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.0647 - mae: 2.9537 - val_loss: 15.2340 - val_mae: 3.2009 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8902 - mae: 2.5203 - val_loss: 11.3159 - val_mae: 2.6246 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1454 - mae: 2.4846 - val_loss: 7.4603 - val_mae: 2.1719 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8301 - mae: 2.0396 - val_loss: 5.2768 - val_mae: 1.8176 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3479 - mae: 2.0901 - val_loss: 5.1665 - val_mae: 1.8543 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2501 - mae: 2.0190 - val_loss: 3.0133 - val_mae: 1.3667 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7298 - mae: 2.0339 - val_loss: 2.7005 - val_mae: 1.3232 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3783 - mae: 1.9177 - val_loss: 1.9443 - val_mae: 1.0985 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5429 - mae: 1.9735 - val_loss: 1.9476 - val_mae: 1.0655 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2558 - mae: 2.0022 - val_loss: 1.9663 - val_mae: 1.0985 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2439 - mae: 1.7505 - val_loss: 1.5854 - val_mae: 0.9622 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0772 - mae: 1.7690 - val_loss: 1.4241 - val_mae: 0.8848 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2041 - mae: 1.7737 - val_loss: 1.3434 - val_mae: 0.8606 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1187 - mae: 1.7929 - val_loss: 0.9956 - val_mae: 0.6778 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8496 - mae: 1.7082 - val_loss: 0.9516 - val_mae: 0.6497 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5707 - mae: 1.6548 - val_loss: 1.0025 - val_mae: 0.7213 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5505 - mae: 1.6711 - val_loss: 0.8973 - val_mae: 0.6286 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3393 - mae: 1.5683 - val_loss: 0.9072 - val_mae: 0.6294 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6269 - mae: 1.6579 - val_loss: 0.9401 - val_mae: 0.6551 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4950 - mae: 1.6076 - val_loss: 0.9229 - val_mae: 0.6362 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6961 - mae: 1.4696 - val_loss: 1.1194 - val_mae: 0.6969 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9778 - mae: 1.5913 - val_loss: 1.1121 - val_mae: 0.6935 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4390 - mae: 1.4411 - val_loss: 0.9380 - val_mae: 0.6205 - learning_rate: 2.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5935 - mae: 1.4811 - val_loss: 0.8366 - val_mae: 0.5743 - learning_rate: 2.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5469 - mae: 1.4468 - val_loss: 0.7698 - val_mae: 0.5647 - learning_rate: 2.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6672 - mae: 1.4784 - val_loss: 0.7655 - val_mae: 0.5873 - learning_rate: 2.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9998 - mae: 1.5639 - val_loss: 0.8037 - val_mae: 0.6257 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1301 - mae: 1.5889 - val_loss: 0.7792 - val_mae: 0.5995 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1864 - mae: 1.6232 - val_loss: 0.7959 - val_mae: 0.6213 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0050 - mae: 1.5572 - val_loss: 0.8203 - val_mae: 0.6444 - learning_rate: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8200 - mae: 1.5140 - val_loss: 0.8018 - val_mae: 0.6283 - learning_rate: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1407 - mae: 1.5700 - val_loss: 0.7830 - val_mae: 0.6133 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1573 - mae: 1.6056 - val_loss: 0.7862 - val_mae: 0.6161 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0631 - mae: 1.5769 - val_loss: 0.8022 - val_mae: 0.6262 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0011 - mae: 1.5779 - val_loss: 0.7873 - val_mae: 0.6190 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5576 - mae: 1.4332 - val_loss: 0.7792 - val_mae: 0.6130 - learning_rate: 1.0000e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7150 - mae: 0.5721\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Fold 2 - MAE: 0.5873, Precision@5: 0.4000\n",
      "\n",
      "Training fold 3/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 219.5498 - mae: 14.7605 - val_loss: 194.8738 - val_mae: 13.9404 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.0371 - mae: 13.2880 - val_loss: 170.2038 - val_mae: 13.0038 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 137.0665 - mae: 11.5031 - val_loss: 136.2626 - val_mae: 11.5710 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 90.4593 - mae: 9.0774 - val_loss: 93.0776 - val_mae: 9.4175 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.5378 - mae: 6.5325 - val_loss: 54.5894 - val_mae: 6.9781 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.7337 - mae: 4.2360 - val_loss: 29.9290 - val_mae: 5.0701 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.9796 - mae: 3.0347 - val_loss: 16.0924 - val_mae: 3.7320 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5262 - mae: 2.1567 - val_loss: 10.8317 - val_mae: 3.0659 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6632 - mae: 2.2705 - val_loss: 7.8604 - val_mae: 2.5761 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0768 - mae: 2.0659 - val_loss: 4.9975 - val_mae: 2.0337 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2704 - mae: 2.0704 - val_loss: 4.7478 - val_mae: 1.9438 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7637 - mae: 1.8318 - val_loss: 2.3432 - val_mae: 1.3168 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6138 - mae: 1.7744 - val_loss: 1.6446 - val_mae: 1.0334 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2616 - mae: 1.9317 - val_loss: 0.9796 - val_mae: 0.7151 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9552 - mae: 1.7183 - val_loss: 0.9407 - val_mae: 0.7032 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8231 - mae: 1.8446 - val_loss: 0.8693 - val_mae: 0.6547 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7953 - mae: 1.6917 - val_loss: 0.8884 - val_mae: 0.6566 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9572 - mae: 1.7279 - val_loss: 0.8012 - val_mae: 0.5927 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1499 - mae: 1.5571 - val_loss: 1.4020 - val_mae: 0.8791 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4038 - mae: 1.6412 - val_loss: 0.8484 - val_mae: 0.6054 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7971 - mae: 1.5065 - val_loss: 0.8594 - val_mae: 0.6223 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9436 - mae: 1.5238 - val_loss: 0.7534 - val_mae: 0.5830 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6693 - mae: 1.6725 - val_loss: 0.6875 - val_mae: 0.5583 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8155 - mae: 1.5084 - val_loss: 0.8749 - val_mae: 0.6556 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9691 - mae: 1.5404 - val_loss: 0.8568 - val_mae: 0.6623 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6981 - mae: 1.5107 - val_loss: 0.7211 - val_mae: 0.5667 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0284 - mae: 1.5639 - val_loss: 0.7659 - val_mae: 0.5928 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0992 - mae: 1.5472 - val_loss: 1.1282 - val_mae: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0804 - mae: 1.5765 - val_loss: 0.9712 - val_mae: 0.7255 - learning_rate: 2.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9109 - mae: 1.5267 - val_loss: 0.8591 - val_mae: 0.6541 - learning_rate: 2.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2726 - mae: 1.3801 - val_loss: 0.7293 - val_mae: 0.5655 - learning_rate: 2.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6298 - mae: 1.4455 - val_loss: 0.6498 - val_mae: 0.5166 - learning_rate: 2.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4204 - mae: 1.4394 - val_loss: 0.6161 - val_mae: 0.4983 - learning_rate: 2.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3563 - mae: 1.3946 - val_loss: 0.5923 - val_mae: 0.4812 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7474 - mae: 1.5425 - val_loss: 0.5869 - val_mae: 0.4721 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3687 - mae: 1.4281 - val_loss: 0.6023 - val_mae: 0.4871 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9120 - mae: 1.3047 - val_loss: 0.5888 - val_mae: 0.4666 - learning_rate: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2386 - mae: 1.4140 - val_loss: 0.5657 - val_mae: 0.4513 - learning_rate: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0519 - mae: 1.5422 - val_loss: 0.5687 - val_mae: 0.4483 - learning_rate: 2.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2560 - mae: 1.3923 - val_loss: 0.5630 - val_mae: 0.4457 - learning_rate: 2.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4372 - mae: 1.4343 - val_loss: 0.5617 - val_mae: 0.4488 - learning_rate: 2.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4118 - mae: 1.4160 - val_loss: 0.5582 - val_mae: 0.4429 - learning_rate: 2.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2726 - mae: 1.3914 - val_loss: 0.5529 - val_mae: 0.4386 - learning_rate: 2.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3666 - mae: 1.4481 - val_loss: 0.5623 - val_mae: 0.4448 - learning_rate: 2.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4222 - mae: 1.4002 - val_loss: 0.5730 - val_mae: 0.4589 - learning_rate: 2.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0300 - mae: 1.3169 - val_loss: 0.5637 - val_mae: 0.4514 - learning_rate: 2.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7956 - mae: 1.2755 - val_loss: 0.5675 - val_mae: 0.4536 - learning_rate: 2.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1370 - mae: 1.3300 - val_loss: 0.5637 - val_mae: 0.4504 - learning_rate: 2.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2483 - mae: 1.3784 - val_loss: 0.5709 - val_mae: 0.4550 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3087 - mae: 1.3974 - val_loss: 0.5678 - val_mae: 0.4517 - learning_rate: 1.0000e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6221 - mae: 0.4592\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x51c7d1e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Fold 3 - MAE: 0.4386, Precision@5: 0.2000\n",
      "\n",
      "Training fold 4/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 221.8518 - mae: 14.8430 - val_loss: 204.7906 - val_mae: 14.2836 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179.9324 - mae: 13.3474 - val_loss: 173.5009 - val_mae: 13.1187 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.7064 - mae: 11.6023 - val_loss: 132.5088 - val_mae: 11.3504 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.4554 - mae: 9.3510 - val_loss: 87.3313 - val_mae: 8.8922 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.4728 - mae: 6.4942 - val_loss: 54.9372 - val_mae: 6.7999 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.7500 - mae: 4.3194 - val_loss: 34.6681 - val_mae: 5.3486 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8846 - mae: 3.6220 - val_loss: 21.1643 - val_mae: 4.1490 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8652 - mae: 2.9340 - val_loss: 11.0013 - val_mae: 2.9671 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1610 - mae: 2.2396 - val_loss: 4.8857 - val_mae: 1.8796 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3992 - mae: 2.2644 - val_loss: 3.2224 - val_mae: 1.4878 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8650 - mae: 1.8976 - val_loss: 2.2755 - val_mae: 1.1888 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4236 - mae: 2.1160 - val_loss: 1.8545 - val_mae: 0.9556 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3277 - mae: 1.9354 - val_loss: 1.8386 - val_mae: 0.9272 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7634 - mae: 1.6922 - val_loss: 1.9289 - val_mae: 0.9527 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2915 - mae: 1.7545 - val_loss: 1.7609 - val_mae: 0.9115 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2141 - mae: 1.8147 - val_loss: 1.6068 - val_mae: 0.8708 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2357 - mae: 1.7226 - val_loss: 1.6859 - val_mae: 0.9131 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8754 - mae: 1.6846 - val_loss: 1.7936 - val_mae: 0.9098 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8211 - mae: 1.7395 - val_loss: 1.5457 - val_mae: 0.8268 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6023 - mae: 1.6892 - val_loss: 1.6056 - val_mae: 0.8388 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0085 - mae: 1.5180 - val_loss: 1.4242 - val_mae: 0.7755 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8944 - mae: 1.7019 - val_loss: 1.6159 - val_mae: 0.8181 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4157 - mae: 1.5951 - val_loss: 1.2773 - val_mae: 0.7532 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0378 - mae: 1.5506 - val_loss: 1.4829 - val_mae: 0.7682 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9054 - mae: 1.4903 - val_loss: 1.4488 - val_mae: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2458 - mae: 1.6227 - val_loss: 1.6327 - val_mae: 0.8506 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7817 - mae: 1.7204 - val_loss: 1.5078 - val_mae: 0.8189 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0563 - mae: 1.5815 - val_loss: 1.5171 - val_mae: 0.8298 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4220 - mae: 1.4189 - val_loss: 1.2571 - val_mae: 0.7142 - learning_rate: 2.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0587 - mae: 1.5748 - val_loss: 1.1511 - val_mae: 0.6808 - learning_rate: 2.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7314 - mae: 1.4312 - val_loss: 1.0917 - val_mae: 0.6621 - learning_rate: 2.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3706 - mae: 1.4116 - val_loss: 1.1108 - val_mae: 0.6720 - learning_rate: 2.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5963 - mae: 1.4059 - val_loss: 1.1098 - val_mae: 0.6875 - learning_rate: 2.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4688 - mae: 1.4536 - val_loss: 1.0781 - val_mae: 0.6715 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3034 - mae: 1.3872 - val_loss: 1.0741 - val_mae: 0.6738 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5751 - mae: 1.4394 - val_loss: 1.0753 - val_mae: 0.6858 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8302 - mae: 1.5287 - val_loss: 1.0368 - val_mae: 0.6660 - learning_rate: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5125 - mae: 1.5229 - val_loss: 1.0816 - val_mae: 0.6867 - learning_rate: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3888 - mae: 1.4415 - val_loss: 1.0421 - val_mae: 0.6700 - learning_rate: 2.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8536 - mae: 1.5328 - val_loss: 1.0270 - val_mae: 0.6621 - learning_rate: 2.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5616 - mae: 1.4742 - val_loss: 1.0177 - val_mae: 0.6520 - learning_rate: 2.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4832 - mae: 1.4337 - val_loss: 1.0111 - val_mae: 0.6433 - learning_rate: 2.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3565 - mae: 1.3867 - val_loss: 1.0121 - val_mae: 0.6414 - learning_rate: 2.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2479 - mae: 1.4313 - val_loss: 1.0368 - val_mae: 0.6520 - learning_rate: 2.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3802 - mae: 1.4381 - val_loss: 1.0554 - val_mae: 0.6608 - learning_rate: 2.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5774 - mae: 1.4647 - val_loss: 1.0278 - val_mae: 0.6510 - learning_rate: 2.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7981 - mae: 1.4880 - val_loss: 1.0416 - val_mae: 0.6540 - learning_rate: 2.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2835 - mae: 1.4096 - val_loss: 1.0520 - val_mae: 0.6621 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4625 - mae: 1.4572 - val_loss: 1.0517 - val_mae: 0.6684 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0708 - mae: 1.3216 - val_loss: 1.0544 - val_mae: 0.6698 - learning_rate: 1.0000e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1833 - mae: 0.6528\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x85dd25160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Fold 4 - MAE: 0.6433, Precision@5: 0.2000\n",
      "\n",
      "Training fold 5/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 202.6393 - mae: 14.1762 - val_loss: 176.3048 - val_mae: 13.2211 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155.7486 - mae: 12.3751 - val_loss: 143.4465 - val_mae: 11.8730 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.4448 - mae: 10.3090 - val_loss: 104.3476 - val_mae: 9.9781 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.9158 - mae: 7.6655 - val_loss: 71.9951 - val_mae: 8.0954 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.6964 - mae: 5.4112 - val_loss: 49.5651 - val_mae: 6.5864 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.4519 - mae: 4.2328 - val_loss: 32.7341 - val_mae: 5.3558 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.2326 - mae: 3.1153 - val_loss: 17.7322 - val_mae: 3.9388 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2821 - mae: 2.4121 - val_loss: 8.9858 - val_mae: 2.7623 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5477 - mae: 2.0043 - val_loss: 5.9716 - val_mae: 2.1881 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7318 - mae: 2.0802 - val_loss: 4.3352 - val_mae: 1.8131 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0460 - mae: 1.7153 - val_loss: 2.9700 - val_mae: 1.3651 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1606 - mae: 1.9794 - val_loss: 2.2874 - val_mae: 1.0683 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0667 - mae: 1.8545 - val_loss: 2.0519 - val_mae: 0.9994 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0632 - mae: 1.7323 - val_loss: 1.7897 - val_mae: 0.8524 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3659 - mae: 1.7532 - val_loss: 1.6254 - val_mae: 0.8498 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2847 - mae: 1.5872 - val_loss: 1.4625 - val_mae: 0.7065 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8529 - mae: 1.6949 - val_loss: 1.3766 - val_mae: 0.7023 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7549 - mae: 1.6807 - val_loss: 1.4826 - val_mae: 0.7142 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9185 - mae: 1.5590 - val_loss: 1.4709 - val_mae: 0.6938 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5965 - mae: 1.6610 - val_loss: 1.5327 - val_mae: 0.7339 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3314 - mae: 1.6007 - val_loss: 1.6159 - val_mae: 0.7750 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6985 - mae: 1.4988 - val_loss: 1.5202 - val_mae: 0.7333 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7069 - mae: 1.4975 - val_loss: 1.3937 - val_mae: 0.6606 - learning_rate: 2.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9003 - mae: 1.7140 - val_loss: 1.3197 - val_mae: 0.6342 - learning_rate: 2.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5317 - mae: 1.4654 - val_loss: 1.3322 - val_mae: 0.6334 - learning_rate: 2.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8158 - mae: 1.5338 - val_loss: 1.3271 - val_mae: 0.6327 - learning_rate: 2.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7268 - mae: 1.4835 - val_loss: 1.3263 - val_mae: 0.6634 - learning_rate: 2.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9835 - mae: 1.5666 - val_loss: 1.3323 - val_mae: 0.6754 - learning_rate: 2.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5204 - mae: 1.4676 - val_loss: 1.3488 - val_mae: 0.6794 - learning_rate: 2.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9512 - mae: 1.5328 - val_loss: 1.3547 - val_mae: 0.6894 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7644 - mae: 1.4911 - val_loss: 1.3537 - val_mae: 0.7000 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3058 - mae: 1.4185 - val_loss: 1.3575 - val_mae: 0.7059 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9819 - mae: 1.4979 - val_loss: 1.3625 - val_mae: 0.7088 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7887 - mae: 1.4863 - val_loss: 1.3400 - val_mae: 0.7066 - learning_rate: 1.0000e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3351 - mae: 0.6211\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Fold 5 - MAE: 0.6342, Precision@5: 0.2000\n",
      "\n",
      "Cross-validation MAE scores: [0.6645761132240295, 0.5873421430587769, 0.43862369656562805, 0.6432734131813049, 0.6341976523399353]\n",
      "Average MAE: 0.5936\n",
      "Cross-validation Precision@5 scores: [0.2, 0.4, 0.2, 0.2, 0.2]\n",
      "Average Precision@5: 0.2400\n",
      "\n",
      "Training final model on all data...\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 221.6791 - mae: 14.8396 - val_loss: 184.4335 - val_mae: 13.5391 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179.7880 - mae: 13.3163 - val_loss: 154.5999 - val_mae: 12.3617 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134.2569 - mae: 11.4042 - val_loss: 124.6556 - val_mae: 11.0403 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.6077 - mae: 8.8752 - val_loss: 86.2437 - val_mae: 9.0071 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46.6873 - mae: 6.2001 - val_loss: 49.2788 - val_mae: 6.4205 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.0034 - mae: 4.3457 - val_loss: 30.3136 - val_mae: 4.7918 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.4814 - mae: 3.2310 - val_loss: 20.0733 - val_mae: 3.8536 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.3040 - mae: 2.7759 - val_loss: 15.4462 - val_mae: 3.4591 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0772 - mae: 2.3708 - val_loss: 10.3565 - val_mae: 2.8808 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2873 - mae: 1.9417 - val_loss: 7.3207 - val_mae: 2.4463 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8489 - mae: 1.8949 - val_loss: 4.9823 - val_mae: 1.9791 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6875 - mae: 1.8370 - val_loss: 3.7611 - val_mae: 1.6630 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2422 - mae: 2.0934 - val_loss: 2.5945 - val_mae: 1.3191 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6047 - mae: 1.8378 - val_loss: 1.8007 - val_mae: 0.9775 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0310 - mae: 1.7531 - val_loss: 1.7252 - val_mae: 0.9096 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5691 - mae: 1.6769 - val_loss: 1.5347 - val_mae: 0.8698 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5882 - mae: 1.6871 - val_loss: 1.3777 - val_mae: 0.7728 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5069 - mae: 1.6902 - val_loss: 1.4171 - val_mae: 0.7535 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7371 - mae: 1.6740 - val_loss: 1.4844 - val_mae: 0.7868 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3570 - mae: 1.6367 - val_loss: 1.4981 - val_mae: 0.7715 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3092 - mae: 1.6095 - val_loss: 1.4017 - val_mae: 0.7452 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1945 - mae: 1.5083 - val_loss: 1.3433 - val_mae: 0.7533 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3533 - mae: 1.6451 - val_loss: 1.3406 - val_mae: 0.7760 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0220 - mae: 1.5655 - val_loss: 1.2572 - val_mae: 0.7535 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9311 - mae: 1.5252 - val_loss: 1.1710 - val_mae: 0.7178 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7878 - mae: 1.7010 - val_loss: 1.1687 - val_mae: 0.7101 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3189 - mae: 1.6532 - val_loss: 1.1259 - val_mae: 0.6679 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8020 - mae: 1.5365 - val_loss: 1.0483 - val_mae: 0.6625 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5857 - mae: 1.4527 - val_loss: 1.1309 - val_mae: 0.6706 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5328 - mae: 1.4484 - val_loss: 1.0831 - val_mae: 0.6435 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5922 - mae: 1.4467 - val_loss: 1.1368 - val_mae: 0.6732 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3526 - mae: 1.4167 - val_loss: 1.2576 - val_mae: 0.7127 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3229 - mae: 1.4047 - val_loss: 1.1386 - val_mae: 0.6617 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5335 - mae: 1.4330 - val_loss: 1.0881 - val_mae: 0.6526 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7299 - mae: 1.5326 - val_loss: 1.0505 - val_mae: 0.6443 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1672 - mae: 1.3961 - val_loss: 1.0031 - val_mae: 0.6330 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4389 - mae: 1.4367 - val_loss: 0.9645 - val_mae: 0.6236 - learning_rate: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0908 - mae: 1.3584 - val_loss: 0.9641 - val_mae: 0.6191 - learning_rate: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8543 - mae: 1.2866 - val_loss: 0.9570 - val_mae: 0.6133 - learning_rate: 2.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6829 - mae: 1.4610 - val_loss: 0.9552 - val_mae: 0.6312 - learning_rate: 2.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9580 - mae: 1.3308 - val_loss: 0.9555 - val_mae: 0.6375 - learning_rate: 2.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4466 - mae: 1.4314 - val_loss: 0.9515 - val_mae: 0.6446 - learning_rate: 2.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0615 - mae: 1.3465 - val_loss: 0.9320 - val_mae: 0.6230 - learning_rate: 2.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6474 - mae: 1.4844 - val_loss: 0.9366 - val_mae: 0.6200 - learning_rate: 2.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6611 - mae: 1.4868 - val_loss: 0.9336 - val_mae: 0.6131 - learning_rate: 2.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9183 - mae: 1.5448 - val_loss: 0.9252 - val_mae: 0.6233 - learning_rate: 2.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1338 - mae: 1.3559 - val_loss: 0.9216 - val_mae: 0.6092 - learning_rate: 2.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0353 - mae: 1.3589 - val_loss: 0.9154 - val_mae: 0.6203 - learning_rate: 2.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0683 - mae: 1.3069 - val_loss: 0.9050 - val_mae: 0.6198 - learning_rate: 2.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8137 - mae: 1.3223 - val_loss: 0.9024 - val_mae: 0.6201 - learning_rate: 2.0000e-04\n",
      "\n",
      "Generating optimized meal plan recommendations...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\n",
      "Top 5 Recommended Meal Plans:\n",
      "\n",
      "Plan 1 - Predicted Score: 16.64\n",
      "Recipes: ['Cinnamon Pound Cake' 'Instant Spiced Tea'\n",
      " 'Japanese-Style Chilled Carbonara Pasta With Bonito Flakes']\n",
      "Nutritional Profile: Protein: 2, Carbs: 2, Vegetables: 2, Dairy: 2\n",
      "\n",
      "Plan 2 - Predicted Score: 16.47\n",
      "Recipes: ['Pork Meatball Banh Mi '\n",
      " 'Sirloin with Roasted Sweet Potatoes, Peppers, and Shiitakes'\n",
      " 'Cranberry Sauce']\n",
      "Nutritional Profile: Protein: 3, Carbs: 6, Vegetables: 5, Dairy: 3\n",
      "\n",
      "Plan 3 - Predicted Score: 16.34\n",
      "Recipes: ['Mints - Altoid Style' 'Individual Chicken Pies' 'Party Mix']\n",
      "Nutritional Profile: Protein: 2, Carbs: 4, Vegetables: 3, Dairy: 0\n",
      "\n",
      "Plan 4 - Predicted Score: 16.29\n",
      "Recipes: ['Chili Chicken Stew' 'Green Beans In Shallot Butter Sauce'\n",
      " 'Stir-Fried Longbeans']\n",
      "Nutritional Profile: Protein: 5, Carbs: 2, Vegetables: 5, Dairy: 1\n",
      "\n",
      "Plan 5 - Predicted Score: 16.19\n",
      "Recipes: [\"Jana'S Church Enchiladas\" 'Cheese Ball' 'Thank You Dessert']\n",
      "Nutritional Profile: Protein: 2, Carbs: 1, Vegetables: 2, Dairy: 6\n",
      "\n",
      "Simulating collaborative filtering elements...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run k-fold cross-validation\n",
    "fold_scores = []\n",
    "fold_precision = []\n",
    "\n",
    "print(\"Starting cross-validation training...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_features)):\n",
    "    print(f\"\\nTraining fold {fold+1}/5...\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train = [X_features[i] for i in train_idx]\n",
    "    X_val = [X_features[i] for i in val_idx]\n",
    "    y_train = y_with_preferences[train_idx]\n",
    "    y_val = y_with_preferences[val_idx]\n",
    "    \n",
    "    # Prepare inputs\n",
    "    train_inputs = prepare_model_inputs(X_train)\n",
    "    val_inputs = prepare_model_inputs(X_val)\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_improved_model()\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_inputs, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(val_inputs, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    val_score = model.evaluate(val_inputs, y_val)[1]  # Get MAE\n",
    "    fold_scores.append(val_score)\n",
    "    \n",
    "    # Calculate precision@5\n",
    "    y_pred = model.predict(val_inputs).flatten()\n",
    "    p_at_5 = precision_at_k(y_val, y_pred, k=5)\n",
    "    fold_precision.append(p_at_5)\n",
    "    \n",
    "    print(f\"Fold {fold+1} - MAE: {val_score:.4f}, Precision@5: {p_at_5:.4f}\")\n",
    "\n",
    "print(f\"\\nCross-validation MAE scores: {fold_scores}\")\n",
    "print(f\"Average MAE: {np.mean(fold_scores):.4f}\")\n",
    "print(f\"Cross-validation Precision@5 scores: {fold_precision}\")\n",
    "print(f\"Average Precision@5: {np.mean(fold_precision):.4f}\")\n",
    "\n",
    "# Train final model on all data\n",
    "print(\"\\nTraining final model on all data...\")\n",
    "all_inputs = prepare_model_inputs(X_features)\n",
    "final_model = build_improved_model()\n",
    "\n",
    "final_history = final_model.fit(\n",
    "    all_inputs, y_with_preferences,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nGenerating optimized meal plan recommendations...\")\n",
    "# Generate candidate meal plans\n",
    "candidate_plans = [create_meal_plan() for _ in range(200)]\n",
    "candidate_features = [get_plan_features(plan) for plan in candidate_plans]\n",
    "candidate_inputs = prepare_model_inputs(candidate_features)\n",
    "\n",
    "# Predict scores\n",
    "predicted_scores = final_model.predict(candidate_inputs).flatten()\n",
    "\n",
    "# Recommend top N plans\n",
    "top_indices = np.argsort(predicted_scores)[-5:][::-1]\n",
    "\n",
    "# View best meal plans\n",
    "print(\"\\nTop 5 Recommended Meal Plans:\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    plan = candidate_plans[idx]\n",
    "    recipes = df.loc[plan, 'title'].values\n",
    "    \n",
    "    # Calculate nutritional profile\n",
    "    nutrition = np.sum([df.loc[recipe_idx, 'nutritional_features'] for recipe_idx in plan], axis=0)\n",
    "    \n",
    "    print(f\"\\nPlan {i+1} - Predicted Score: {predicted_scores[idx]:.2f}\")\n",
    "    print(f\"Recipes: {recipes}\")\n",
    "    print(f\"Nutritional Profile: Protein: {nutrition[0]}, Carbs: {nutrition[1]}, Vegetables: {nutrition[2]}, Dairy: {nutrition[3]}\")\n",
    "\n",
    "# IMPROVEMENT 8: Collaborative Filtering Elements (Simulated)\n",
    "print(\"\\nSimulating collaborative filtering elements...\")\n",
    "# In a real system, you would have user ratings for meal plans\n",
    "# Here we'll simulate user ratings based on our existing data\n",
    "\n",
    "# Create a few simulated users with different preferences\n",
    "user_profiles = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'vegetarian': False,\n",
    "        'favorite_ingredients': ['chicken', 'garlic', 'cheese'],\n",
    "        'disliked_ingredients': ['mushroom', 'olive']\n",
    "    },\n",
    "    {\n",
    "        'id': 2,\n",
    "        'vegetarian': True,\n",
    "        'favorite_ingredients': ['tofu', 'spinach', 'broccoli'],\n",
    "        'disliked_ingredients': ['cheese', 'cream']\n",
    "    },\n",
    "    {\n",
    "        'id': 3,\n",
    "        'vegetarian': False,\n",
    "        'favorite_ingredients': ['beef', 'potato', 'onion'],\n",
    "        'disliked_ingredients': ['cilantro', 'spicy']\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ededca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulated user ratings...\n",
      "Training hybrid recommendation model...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentma/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 81.5813 - mae: 8.8909 - val_loss: 67.9858 - val_mae: 8.1690\n",
      "Epoch 2/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.6650 - mae: 7.3700 - val_loss: 45.0156 - val_mae: 6.6104\n",
      "Epoch 3/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.1592 - mae: 5.3852 - val_loss: 22.2923 - val_mae: 4.5518\n",
      "Epoch 4/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.2798 - mae: 3.5503 - val_loss: 6.7192 - val_mae: 2.3084\n",
      "Epoch 5/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0279 - mae: 2.0787 - val_loss: 3.3637 - val_mae: 1.4933\n",
      "Epoch 6/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5820 - mae: 1.8326 - val_loss: 3.6926 - val_mae: 1.6143\n",
      "Epoch 7/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2728 - mae: 2.1091 - val_loss: 3.6913 - val_mae: 1.6263\n",
      "Epoch 8/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8761 - mae: 2.1803 - val_loss: 3.2290 - val_mae: 1.4990\n",
      "Epoch 9/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4957 - mae: 1.8073 - val_loss: 3.2700 - val_mae: 1.5181\n",
      "Epoch 10/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5141 - mae: 1.6936 - val_loss: 3.2810 - val_mae: 1.5252\n",
      "Epoch 11/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1763 - mae: 2.0889 - val_loss: 2.3140 - val_mae: 1.2098\n",
      "Epoch 12/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6927 - mae: 1.9764 - val_loss: 2.2716 - val_mae: 1.2081\n",
      "Epoch 13/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0484 - mae: 1.8020 - val_loss: 2.0333 - val_mae: 1.1348\n",
      "Epoch 14/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7232 - mae: 1.7141 - val_loss: 2.0160 - val_mae: 1.1390\n",
      "Epoch 15/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4052 - mae: 1.8941 - val_loss: 1.9035 - val_mae: 1.1078\n",
      "Epoch 16/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6529 - mae: 1.9229 - val_loss: 1.8082 - val_mae: 1.0803\n",
      "Epoch 17/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5831 - mae: 1.7131 - val_loss: 1.8234 - val_mae: 1.0942\n",
      "Epoch 18/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9447 - mae: 1.7683 - val_loss: 1.9982 - val_mae: 1.1607\n",
      "Epoch 19/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2330 - mae: 2.0699 - val_loss: 1.6632 - val_mae: 1.0343\n",
      "Epoch 20/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7632 - mae: 2.0225 - val_loss: 1.7232 - val_mae: 1.0519\n",
      "\n",
      "Generating personalized recommendations for each user profile:\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\n",
      "Personalized Recommendations for User 1\n",
      "User profile: Non-vegetarian, Likes: chicken, garlic, cheese, Dislikes: mushroom, olive\n",
      "  Plan 1 - Predicted Rating: 11.26\n",
      "  Recipes: ['One Dish Macaroni And Beef(Microwave)  ' 'Philippine Butter Cookies'\n",
      " 'Gingerbread Syrup']\n",
      "  Plan 2 - Predicted Rating: 10.95\n",
      "  Recipes: ['Almond Crescents(Cookies)  '\n",
      " 'Nutella, Banana, And Croissant Pudding Recipe' 'Lemon Pound Cake']\n",
      "  Plan 3 - Predicted Rating: 10.91\n",
      "  Recipes: [\"See'S Fudge\" 'Kentucky Pound Cake' 'Cannellini Bean Dip']\n",
      "  Plan 4 - Predicted Rating: 10.88\n",
      "  Recipes: ['Monkey Bread' 'Kugel' 'Cran-Orange-Apple Pie']\n",
      "  Plan 5 - Predicted Rating: 10.86\n",
      "  Recipes: ['Vanilla ButterCream' 'Cheddar-Chive Bread (Bread Machine)'\n",
      " 'Summer Fruit Basket']\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Personalized Recommendations for User 2\n",
      "User profile: Vegetarian, Likes: tofu, spinach, broccoli, Dislikes: cheese, cream\n",
      "  Plan 1 - Predicted Rating: 8.87\n",
      "  Recipes: ['Pecan Pie Cake' 'Old-Fashioned Cookies'\n",
      " 'Crisp-Braised Duck Legs with Aromatic Vegetables']\n",
      "  Plan 2 - Predicted Rating: 8.68\n",
      "  Recipes: [\"Rachel'S Pound Cake\" 'Swedish Breakfast Crackers' 'Chimichangas']\n",
      "  Plan 3 - Predicted Rating: 8.59\n",
      "  Recipes: ['Chocolate Delight' 'Bean Vegetable Soup' 'Chicken Wingettes']\n",
      "  Plan 4 - Predicted Rating: 8.56\n",
      "  Recipes: ['Chili Rellenos' 'Quick And Easy Cornbread' 'Chocolate Eclair Cake']\n",
      "  Plan 5 - Predicted Rating: 8.35\n",
      "  Recipes: ['Winning Recipe Mini Coconut Cupcakes with Poppy Seed Crust, Muscat Raisin Filling, and Parsley Icing with Toasted Coconut, Flax and Poppy Seed Toffee, and Organic Roses'\n",
      " \"Mom's Best Meatloaf\" 'Fluffy Rice And Chicken']\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Personalized Recommendations for User 3\n",
      "User profile: Non-vegetarian, Likes: beef, potato, onion, Dislikes: cilantro, spicy\n",
      "  Plan 1 - Predicted Rating: 11.21\n",
      "  Recipes: ['Dump Cake' 'Hamburger Soup' \"Granny Minor'S Icebox Fruit Cake\"]\n",
      "  Plan 2 - Predicted Rating: 10.67\n",
      "  Recipes: ['An Easter Brunch(\"Cheese Roll-Ups\")  ' 'Corn Bread' \"Mom'S Granola \"]\n",
      "  Plan 3 - Predicted Rating: 10.62\n",
      "  Recipes: ['Pound Cake' 'Sausage Finger Sandwiches' 'Delicious Chicken Salad']\n",
      "  Plan 4 - Predicted Rating: 10.57\n",
      "  Recipes: ['Golden Tangerine Nut Bread' 'Chocolate Nut Brownies'\n",
      " 'Tropical Trail Mix']\n",
      "  Plan 5 - Predicted Rating: 10.52\n",
      "  Recipes: ['Braciola With Noodles' \"Doretha'S Casserole\" 'Coconut Joe Pound Cake']\n",
      "\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to simulate a user's rating for a meal plan\n",
    "def simulate_user_rating(user, plan):\n",
    "    base_score = calculate_meal_balance_score(plan)\n",
    "    \n",
    "    # Apply user preferences\n",
    "    for recipe_idx in plan:\n",
    "        ingredients_text = ' '.join(df.loc[recipe_idx, 'ingredients']).lower()\n",
    "        \n",
    "        # Check vegetarian preference\n",
    "        if user['vegetarian']:\n",
    "            meat_keywords = ['chicken', 'beef', 'pork', 'fish', 'meat', 'turkey']\n",
    "            if any(meat in ingredients_text for meat in meat_keywords):\n",
    "                base_score -= 2.0\n",
    "        \n",
    "        # Check favorite ingredients\n",
    "        for ingredient in user['favorite_ingredients']:\n",
    "            if ingredient in ingredients_text:\n",
    "                base_score += 0.3\n",
    "        \n",
    "        # Check disliked ingredients\n",
    "        for ingredient in user['disliked_ingredients']:\n",
    "            if ingredient in ingredients_text:\n",
    "                base_score -= 0.5\n",
    "    \n",
    "    # Normalize to 1-10 scale\n",
    "    return max(1, min(10, base_score))\n",
    "\n",
    "# Generate simulated ratings data\n",
    "print(\"Generating simulated user ratings...\")\n",
    "ratings_data = []\n",
    "for user in user_profiles:\n",
    "    # Each user rates 50 random meal plans\n",
    "    for _ in range(50):\n",
    "        plan = create_meal_plan()\n",
    "        rating = simulate_user_rating(user, plan)\n",
    "        \n",
    "        # Calculate average plan embedding\n",
    "        plan_embedding = np.mean([df.loc[idx, 'embedding'] for idx in plan], axis=0)\n",
    "        \n",
    "        ratings_data.append({\n",
    "            'user_id': user['id'],\n",
    "            'plan_embedding': plan_embedding,\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "# Define a hybrid model with collaborative filtering\n",
    "def build_hybrid_model(embedding_dim=50, num_users=3):\n",
    "    # Content-based part (recipe embeddings)\n",
    "    recipe_input = layers.Input(shape=(embedding_dim,))\n",
    "    recipe_features = layers.Dense(32, activation='relu')(recipe_input)\n",
    "    \n",
    "    # Collaborative filtering part\n",
    "    user_input = layers.Input(shape=(1,))\n",
    "    user_embedding = layers.Embedding(num_users + 1, 32, input_length=1)(user_input)\n",
    "    user_embedding = layers.Flatten()(user_embedding)\n",
    "    \n",
    "    # Combine both approaches\n",
    "    concatenated = layers.Concatenate()([recipe_features, user_embedding])\n",
    "    x = layers.Dense(32, activation='relu')(concatenated)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    \n",
    "    model = models.Model(inputs=[recipe_input, user_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Prepare data for hybrid model\n",
    "X_recipe = np.array([data['plan_embedding'] for data in ratings_data])\n",
    "X_user = np.array([data['user_id'] for data in ratings_data])\n",
    "y_rating = np.array([data['rating'] for data in ratings_data])\n",
    "\n",
    "# Train hybrid model\n",
    "print(\"Training hybrid recommendation model...\")\n",
    "hybrid_model = build_hybrid_model()\n",
    "hybrid_history = hybrid_model.fit(\n",
    "    [X_recipe, X_user], \n",
    "    y_rating,\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Generate personalized recommendations for a specific user\n",
    "def generate_personalized_recommendations(user_id, num_recommendations=5):\n",
    "    # Generate candidate plans\n",
    "    candidate_plans = [create_meal_plan() for _ in range(100)]\n",
    "    \n",
    "    # Prepare input for prediction\n",
    "    candidate_embeddings = np.array([\n",
    "        np.mean([df.loc[idx, 'embedding'] for idx in plan], axis=0)\n",
    "        for plan in candidate_plans\n",
    "    ])\n",
    "    \n",
    "    user_ids = np.full(len(candidate_plans), user_id)\n",
    "    \n",
    "    # Predict ratings\n",
    "    predicted_ratings = hybrid_model.predict([candidate_embeddings, user_ids]).flatten()\n",
    "    \n",
    "    # Get top recommendations\n",
    "    top_indices = np.argsort(predicted_ratings)[-num_recommendations:][::-1]\n",
    "    \n",
    "    return [candidate_plans[i] for i in top_indices], predicted_ratings[top_indices]\n",
    "\n",
    "# Generate personalized recommendations for each user\n",
    "print(\"\\nGenerating personalized recommendations for each user profile:\")\n",
    "for user in user_profiles:\n",
    "    user_id = user['id']\n",
    "    recommended_plans, predicted_ratings = generate_personalized_recommendations(user_id)\n",
    "    \n",
    "    print(f\"\\nPersonalized Recommendations for User {user_id}\")\n",
    "    print(f\"User profile: {'Vegetarian' if user['vegetarian'] else 'Non-vegetarian'}, \" + \n",
    "          f\"Likes: {', '.join(user['favorite_ingredients'])}, \" + \n",
    "          f\"Dislikes: {', '.join(user['disliked_ingredients'])}\")\n",
    "    \n",
    "    for i, (plan, rating) in enumerate(zip(recommended_plans, predicted_ratings)):\n",
    "        recipes = df.loc[plan, 'title'].values\n",
    "        print(f\"  Plan {i+1} - Predicted Rating: {rating:.2f}\")\n",
    "        print(f\"  Recipes: {recipes}\")\n",
    "\n",
    "print(\"\\nModel training and evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
